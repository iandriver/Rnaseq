<html>
<head>
<title>RNASeq Pipeline Documentation</title>
<style>
.red_text { color: red }
.blue_text { color: blue }
.green_text { color: green }
</style>
</head>
<body>

<h1>RNA-Seq Pipeline Documentation</h1>

FAQ:
<ul>
<li><a href="#what_it_does">What it does.</a></li>
<li><a href="#how_it_works">How it works.</a></li>
<li><a href="#how_to_install">How to install the software</a></li>
<li><a href="#available_pipelines">How to see what pipelines are available</a></li>
<li><a href="#pipeline_contents">How to see what steps are in a pipeline</a></li>
<li><a href="#how_to_launch">How to launch a pipeline</a></li>
<li><a href="#readsets">What is a "readset"?</a></li>
<li><a href="#multiple_files">How do I run the pipeline on multiple files all at once?</a></li>
<li><a href="#working_dir">What are "working directories" and how are they determined?</a></li>
<li><a href="#notifications">How do I know when my pipeline is finished?</a></li>
<li><a href="#results">How do I tell what the pipeline actually did?</a></li>
<li><a href="#status">How do I examine the status of my pipeline?</a></li>
<li><a href="#errors">Was the pipeline successful?</a></li>
<li><a href="#performance_stats">How long did my pipeline take to run?</a></li>
<li><a href="#rerunning">Re-running a failed pipeline</a></li>
<li><a href="#modifying_pipelines">How do I change the steps of a pipeline?</a></li>
<li><a href="#"></a></li>
<li><a href="#"></a></li>
<li><a href="#"></a></li>

</ul>

<div id="what_it_does"><h2>What it does.</h2>

<p>The purpose of the RNA-Seq pipeline is two-fold.  </p>

<p>The first purpose is to provide a tool to biologists that
simplifies the process of analyzing the large amount of RNA-Seq data
generated by such experiments.  Such analysis is typically performed
in a step-wise fasion, with each step implemented by a separate,
pre-configured script.  Examples of steps might include assembly of
transcripts, gene expression quantification, or identification of
splicing events.  This pipeline framework allows such scripts to be
grouped together into one batch job (suitable for running on a desktop
or cluster), with appropriate parameters for each script in place.</p>

<p>The second purpose of the pipeline is to allow more sophisticated users to alter
the contents of the pipeline (scripts, parameters, inputs) in order to compare
the performance of various tools used within the pipeline.  A mechanism for
recording the performamce of each step is provided, as well as provenance for
each intermediate data file generated.</p>

</div>

<div id="how_it_works"><h2>How it works.</h2>
<p>The basic operation of the pipeline software is to convert a group of
text-based configuration files (YAML format) into a shell script that can be run
on a desktop computer or cluster.  The configuration files separate information
in a modular way.  Different files describe the data to be analyzed,
each step of the pipeline, how the steps fit together to form the overall
pipeline, and a final file that defines "global" values (independent of any
specific pipeline).  The pipeline software then assembles the data in these
configuration files into a runnable shell script and launches the job on the
desired hardware configuration.</p>
</div>

<div id="how_to_install"><h2>How to install the software</h2></div>

<div id="available_pipelines"><h2>How to see what pipelines are available</h2>
<p>The software contains several pre-configured ("canned") pipelines that can be run.
To get a list of the available pipelines, type 'rnaseq ls' at the command line.</p>

<p>Each pipeline takes an input file and creates several output files (but see <a href='#readsets'>
here</a> for information on how to process multiple data files at once).</p>
</div>

<div id="pipeline_contents"><h2>How to see what steps are in a pipeline</h2>
<p>Type 'rnaseq ls -p &lt;pipeline&gt;' to get a list of the steps in a pipeline,
and a list of how many times that pipeline has been run.  </p>

<p>fixme: how to find out exactly what each step does, without having to look at the shell script.</p>
</div>

<div id='readsets'><h2>What is a "readset"?</h2>
<p>In order to process your data, the pipeline has to know a certain
amount of information about it including:<ul> 

<li>Where your data is located (ie, where are the data files);</li> 
<li>What directory you want to store the results in;</li> 
<li>A 'label' by which you can refer to the pipeline run.  That is,
consider when you run the same pipeline on completely different sets
of data.  It would be convenient to have a short name by which to
identify the results of the run, and the label serves that
purpose.</li> 
<li>Other pipeline-specific information: This can very
from pipeline to pipeline, but some examples might be the length of
the reads, the organism in question, and so on.</li>
</ul>
</p>
<p>To specify all this information, you have to create a "readset" file.
This file is expected to be in <a href='http://en.wikipedia.org/wiki/YAML#Sample_document'>YAML</a>
format.  An example might look like this:</p>
<pre>
reads_file: /proj/hoodlab/share/vcassen/sandbox/s_6_export.1M.txt
label: my data
description: this is a sample readset
org: mouse
readlen: 75
working_dir: rnaseq_wf
</pre>

<p>This example specifies the data file to be processed ('reads_file'),
a label by which to refer to the readset ('my data'),
an optional description, organism ('org'), read length ('readlen'), and a
working directory ('working_dir').  The 'reads_file' and 'label' entries are
require, although the 'label' may be specified on the command line using the 
'--label' (or '-l') flag.
</p>

<p>In order to create a readset file, use a text editor or word
processor.  However, make sure that you save the readset in 'text'
mode, which doesn't have any formatting information associated with
it.  If you are warned that you might loose formatting information,
that is ok.  You can also use the Unix programs 'cat', 'more', or
'less' to examine your readset file to insure no formatting
information is embedded in the file.  Type 
<pre>less &lt;filename&gt;</pre> (substituting "&lt;filename&gt;" for the actual
name of your file), and what you see should be the same as what you
have in your editor, without other words or special
characters.</p>

</div>

<div id='multiple_files'><h2>How do I run the pipeline on multiple files all at once?</h2>
<p>The <code>reads_file</code> entry in a readset file may contain
"file globs".  These are special patterns that use wildcard characters
to specify patterns that match the names of multiple files.  See <a
href='http://docstore.mik.ua/orelly/unix/upt/ch15_02.htm'>this
link</a> for details, but the basics are:<ul>
<li><code>'*'</code>: match zero or more characters.  For example, '*.txt' would match any filename ending in '.txt'.</li>
<li><code>'+'</code>: match one or more characters.  For example, 'file+.txt' would match any filename starting with 'file', ending in '.txt', and having at least one character in between.  For example, 'file1.txt' would match, but not 'file.txt' or 'data.txt'.</li>
<li><code>'?'</code>: match exactly one character.  For example, 'file?.txt' would match 'file1.txt' or 'file2.txt', but not 'file10.txt' or 'file.txt'.</li>
<li><code>'[x-y]'</code>: match a range of characters.  For example, 'file_[a-z].txt' would match 'file_c.txt', but not 'file_1.txt', 'file.txt', or 'file_az.txt'</li>
</ul>
Also note that constructs can be combined.  For example, <code>file[a-z]+.txt</code> would match any file name that started with 'file' followed by one or more characters between 'a' and 'z', and ended in '.txt'.
</p>

<p>So if the data files that you want to process can be described with
a file glob, you can use that file glob in the 'reads_file' entry of
the readset to cause each file to be processed in it's own pipeline
job.  For example, if you had six files, all in a directory named,
say, "/path/to/my/rnaseq_data" and each file was of the form "data1.fq",
"data2.fq", ..., "data6.fq", then your reads_files entry would like this:
<pre>
reads_file: /path/to/my/rnaseq_data/data[1-6].fq
</pre>
</div>

<div id='working_dir'><h2>What are "working directories" and how are they determined?</h2>
<p>In general, pipelines can produce a lot of data contained in many
different files.  You may not want these data files to reside in the
same directory (folder) as the data itself.  Using a 'working
directory', you can specify where you'd like these data to be created.
Working directories can be relative to the location of the data files,
or somewhere completely different.  The label of the readset can serve
as the name of the working directory as well.  And finally, if
multiple runs (eg with different parameters) of the same pipeline on
the same readset are desired, and you don't want to over write the
results of each run, a working directory based on a timestamp of when
the run occured can be specified.

Working directories are specified in the readset.
</div>


<div id="how_to_launch"><h2>How to launch a pipeline</h2>
<p>In order to launch a pipeline, you give run the pipeline software providing two key pieces of information: 
<ul>
<li>the pipeline you want to run, and</li>
<li>the data you want processed</li>
</ul>
</p>
<p>The basic format of the command is:
<div><code>
rnaseq run -p &lt;pipeline&gt; -r &lt;readset&gt;
</code></div>
</p>
<p>Each of these two items is defined by a configuration file.  The pipeline configuration files are pre-written
and, unless you need to change or customize the pipeline, may be used as is.  However, you will have to create a 
simple configuration file called a <a href='#readsets'>readset</a> that describes your data.
</p>
<p>
Once you have decided which pipeline you want to run and have created
your readset, you launch the pipeline by typing the command shown just
above.  See the <a href='#reference'>reference</a> section for a list
of added options that can modify how your pipeline is run.

</p>
</div>

<div id="notifications"><h2>How do I know when the pipeline is finished?</h2></div>

<p>If you are launching the pipeline on your desktop computer, you can only tell when the pipeline is 
finished when the command prompt returns, just as you would with any other program or script.
(fixme: feature request for optional email notification when running on the desktop).
</p>

<p>If you launch your job to the cluster (using the <a
href='#reference'>--cluster</a> flag), however, email will automatically be
sent to you when your pipeline starts and when it finishes.  Of note, the email
you receive when your cluster job finishes will contain some statistics about how long the job took, how
much memory it used, and what it's exit status was.  See <a href='#errors'>here</a> for more details.

<div id="results"><h2>How do I tell what the pipeline actually did?</h2></div>
<div id="#status"><h2>How do I examine the status of my pipeline?</h2></div>
<div id="errors"><h2>Was the pipeline successful?</h2></div>
<div id="performance_stats"><h2>How long did my pipeline take to run?</h2></div>

All of these questions can be answered by doing one of the following:
<ul>
<li>rnaseq ls -p &lt;pipeline&gt; -l &lt;label&gt;

<p>You can use the <code>rnaseq ls -l &lt;label&gt;</code>
command to check the status of any pipeline, running or finished.  It
will tell you which steps were run, how long each step took, and what
files were produced.  If the pipeline is currently running, it will
tell you which step is currently being executed.  See the <a
href='#reference'>reference</a> section for details.
</p>

</li>
<li>Logs

<p>Every pipeline run produces two log files.  One file captures the
normal output of the pipeline (stdout), and the other catches error
output (stderr).  These files are created in the <a
href="working_dir">working directory</a> of the pipeline.  The name
of each file is the name of the pipeline (as specified with the -p
flag) suffixed with '.out' or '.err', respectively.</p>

<p>So for example, if your <a href='#readsets'>readset</a> specifies
that your data files are in <span
class='red_text'>/some/path/in/your/computer</span>/s_1_export.txt,
and it also specifies 'working_dir:<span class='blue_text'>
rnaseq_wf</span>', and you run a pipeline named <span
class='green_text'>"gene_exp"</span>, then the output log will have
the names <span
class='red_text'>/some/path/in/your/computer/</span><span
class='blue_text'>rnaseq_wf/</span><span
class='green_text'>gene_exp</span>.out.  Likewise, the error log will
have the same name, except with a '.err' suffix instead of '.out'.
</p>
</li>

</ul>

<p>There are two ways to tell if your pipeline ran successfully.</p>

<p>As mentioned in the <a href="#notifications">notifications</a> section, depending on how you launched
your pipeline, you may receive an email notification (if you ran your pipeline on a cluster).  If
so, that email will contain an exit code indicating the success of your pipeline job.  An exit code
of '0' indicates success, anything else indicates failure.</p>

<p>If you ran your job on the command line, the exit code is the same as that of any other 
program.  On Unix-type systems, that value can be found in the '$?' environment variable.  Again, 
'0' indicates success and anything else contains failure.<p>

Of more use are the output and error logs.  See <a href='#notifications'>here</a> for more details.

<div id="rerunning"><h2>Re-running a failed pipeline</h2>
<p>To re-launch a failed pipeline, presumably after fixing the error
that caused the pipeline to fail in the first place, just use the <a href='#how_to_launch'>same
command</a> as you used originally.  The pipeline software is smart enough
to know not to re-create steps that were already run successfully,
assuming the outputs of those steps are still present on the
filesystem.  Use the '-f' or '--force' command line option to force
all the steps to be re-run regardless of whether they are up to date.</p>
</div>


<div id="modifying_pipelines"><h2>How do I change the steps of a pipeline?</h2></div>


<div id='reference'><h2>Reference</h2>
<ul>
<li><code>rnaseq run</code>
<li><code>rnaseq ls</code>
</li>
</ul>
</div>


</div>
</body>
</html>